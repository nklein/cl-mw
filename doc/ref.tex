%% Copyright 2010 Peter K. Keller (psilord@cs.wisc.edu)
%% 
%% Licensed under the Apache License, Version 2.0 (the "License"); you
%% may not use this file except in compliance with the License. You may
%% obtain a copy of the License at
%% 
%% \indent http://www.apache.org/licenses/LICENSE-2.0
%% 
%% Unless required by applicable law or agreed to in writing, software
%% distributed under the License is distributed on an "AS IS" BASIS,
%% WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express
%% or implied. See the License for the specific language governing
%% permissions and limitations under the License.


\documentclass[titlepage,12pt]{book}

\usepackage{tipa}			% for \textpipe 
\usepackage{textcomp}		% for \textdegree
\usepackage{listings}		% for the lisp/barelisp environment
\usepackage{microtype}		% To make things slightly more pretty
\usepackage{xspace}			% a life saver
%\usepackage[T1]{fontenc}	% make underscores show up nice. Bad with pdflatex.
\usepackage{html}			% For Latex2html

% latex2html really messes up the listings package, I'm not sure what to do
% about that yet...
%\begin{htmlonly}
%  \usepackage{moreverb}
%  \providecommand{\lisp}[2][]{\begin{boxedverbatim}#2\end{boxedverbatim}}
%  \providecommand{\barelisp}[2][]{\begin{boxedverbatim}#2\end{boxedverbatim}}
%\end{htmlonly}

\usepackage{hyperref}		% For PDF generation MUST BE LAST
\usepackage[all]{hypcap}	% Except for this, if I'm using hyperref
							% Useful to link against figures and captions at
							% the top of the figure/caption instead of the
							% bottom.

\hypersetup{
	linktocpage,
	citecolor=black,
	filecolor=black,
	linkcolor=blue,
	urlcolor=black,
	colorlinks=true
}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Various macros
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%%%%%%%%%
% Latexery
%%%%%%%%%
\newcommand{\phlabel}[1]{\phantomsection\label{#1}}

%%%%%%%%%
% Sigh. Font alterations for latex versus web pages...
% First arguments means what'll be in the latex, second means what'll be in
% the latex2html.
%%%%%%%%%
\newcommand{\xfootnotesize}{\latexhtml{\footnotesize}{}}
\newcommand{\xsmall}{\latexhtml{\small}{}}
\newcommand{\xnormalsize}{\latexhtml{\normalsize}{}}

%%%%%%%%%
% abbreviations, yay xspace!
%%%%%%%%%
\newcommand{\sbcl}{SBCL\xspace}
\newcommand{\mw}{Master-Slave\xspace}
\newcommand{\clmw}{\xsmall\textsc{CL-MW}\xnormalsize\xspace}
\newcommand{\package}[1]{\mbox{:\uppercase{\xsmall\texttt{#1}\xnormalsize}} package\xspace}
\newcommand{\mwpackage}{\package{CL-MW}}
\newcommand{\sa}{\textit{slave algorithm}\xspace}
\newcommand{\ma}{\textit{master algorithm}\xspace}
\newcommand{\ta}{\textit{task algorithm}\xspace}
\newcommand{\Ta}{\textit{Task algorithm}\xspace}
\newcommand{\sas}{\textit{slave algorithm}s\xspace}
\newcommand{\Sas}{\textit{Slave algorithm}s\xspace}
\newcommand{\mas}{\textit{master algorithm}s\xspace}
\newcommand{\Mas}{\textit{Master algorithm}s\xspace}
\newcommand{\tas}{\textit{task algorithm}s\xspace}
\newcommand{\Tas}{\textit{Task algorithm}s\xspace}
\newcommand{\tp}{\textit{task policy}\xspace}
\newcommand{\rfile}{\textit{resource file}\xspace}
\newcommand{\un}{\texttt{:unordered}\xspace}
\newcommand{\inter}{\texttt{:intermingle}\xspace}
\newcommand{\ord}{\texttt{:ordered}\xspace}
\newcommand{\tag}{\texttt{:tag}\xspace}

%%%%%%%%%
%%The usual suspects
%%%%%%%%%
\newcommand{\dash}{\texttt{-}}

%\newcommand{\func}[1]{\xsmall\mbox{\uppercase{\texttt{#1}}}\xnormalsize\xspace}
%\newcommand{\macro}[1]{\xsmall\mbox{\uppercase{\texttt{#1}}}\xnormalsize\xspace}
%\newcommand{\genmacro}[2]{\xsmall\mbox{\uppercase{\texttt{#1\textit{#2}}}}\xnormalsize\xspace}
%\newcommand{\genmacroname}[1]{\small\mbox{\uppercase{\texttt{#1\textit{name}}}}\normalsize\xspace}

\newcommand{\func}[1]{\mbox{\texttt{#1}}\xspace}
\newcommand{\macro}[1]{\mbox{\texttt{#1}}\xspace}
\newcommand{\genmacro}[2]{\mbox{\texttt{#1\textit{#2}}}\xspace}
\newcommand{\genmacroname}[1]{\mbox{\texttt{#1\textit{name}}}\xspace}

\newcommand{\syscall}[1]{\mbox{\texttt{#1()}}\xspace}
\newcommand{\file}[1]{\texttt{#1}\xspace}
\newcommand{\bool}[1]{\texttt{#1}\xspace}
\newcommand{\bold}[1]{\textbf{#1}\xspace}
\newcommand{\opt}[1]{\texttt{#1}\xspace}
\newcommand{\val}[1]{\textit{#1}\xspace}
\newcommand{\var}[1]{\texttt{#1}\xspace}
\newcommand{\EnvVar}[1]{\texttt{#1}\xspace}
\newcommand{\Option}[1]{\dash\dash\texttt{#1}}
\newcommand{\OptionV}[2]{\dash\dash\texttt{#1} \textit{#2}}
\newcommand{\key}{\texttt{\&key}\xspace}
\newcommand{\rest}{\texttt{\&rest}\xspace}
\newcommand{\optional}{\texttt{\&optional}\xspace}
\newcommand{\keyword}[1]{\texttt{:#1}\xspace}

%%%%%%%%%
% Meta-commentary
%%%%%%%%%
\newcommand{\Todo}{\begin{center}\fbox{\textbf{TODO}}\end{center}}
\newcommand{\Note}{\texttt{\underline{Note}:}\xspace}
\newcommand{\Warn}{\texttt{\underline{Warning}:}\xspace}
\newcommand{\Important}{\texttt{\underline{Important}:}\xspace}
\newcommand{\Limitation}{\texttt{\underline{Limitation}:}\xspace}

%%%%%%%%%
% The API list layout in the technical section
%%%%%%%%%
\newcommand{\apiheader}[1]{\begin{center}\underline{#1}\end{center}}
\newcommand{\apifunc}[2]{\noindent\xsmall\texttt{(#1)}\hspace*{\fill}\xnormalsize\texttt{#2}}
\newenvironment{apientry}[2]
	{\apifunc{#1}{#2}\begin{quotation}}
	{\end{quotation}}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Environments
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%
% A pile of lisp just bare in the code with no annotations or labels.
%%%%%%%%%

\lstnewenvironment{barelisp}[1][]
{\lstset{
language=Lisp,
% the size of the fonts that are used for the code
basicstyle=\small,
keywordstyle=\ttfamily,
identifierstyle=\ttfamily,
commentstyle=\ttfamily,
stringstyle=\ttfamily,
% where to put the line-numbers
%numbers=left,
% the step between two line-numbers. If it's 1 each line will be numbered
%stepnumber=2,
% how far the line-numbers are from the code
%numbersep=5pt,
% show spaces adding particular underscores
showspaces=false,
% underline spaces within strings
showstringspaces=false,
% show tabs within strings adding particular underscores
showtabs=false,
% put various lines around the code
%frame=tb,
% sets default tabsize to 2 spaces
tabsize=2,
% sets the caption-position to bottom
captionpos=b,
% subtract the amount of space used for the caption since I don't have one.
belowskip=-12pt,
% sets automatic line breaking
breaklines=true,
% sets if automatic breaks should only happen at whitespace
breakatwhitespace=true,
% show the filename of files included with \lstinputlisting; also 
% try caption instead of title
title=\lstname,
% if you want to add more keywords to the set
%morekeywords={*,...},
% Follow the chapter numbers
numberbychapter=true,
#1
}}
{}

%%%%%%%%%
% A pile of lisp in the code with a box around it and a caption
%%%%%%%%%
\lstnewenvironment{lisp}[1][]
{\lstset{
language=Lisp,
% the size of the fonts that are used for the code
basicstyle=\small,
keywordstyle=\ttfamily,
identifierstyle=\ttfamily,
commentstyle=\ttfamily,
stringstyle=\ttfamily,
% where to put the line-numbers
%numbers=left,
% the step between two line-numbers. If it's 1 each line will be numbered
%stepnumber=2,
% how far the line-numbers are from the code
%numbersep=5pt,
% show spaces adding particular underscores
showspaces=false,
% underline spaces within strings
showstringspaces=false,
% show tabs within strings adding particular underscores
showtabs=false,
% put various lines around the code
frame=tblr,
% sets default tabsize to 2 spaces
tabsize=2,
% sets the caption-position to bottom
captionpos=t,
% sets automatic line breaking
breaklines=true,
% sets if automatic breaks should only happen at whitespace
breakatwhitespace=true,
% show the filename of files included with \lstinputlisting; also 
% try caption instead of title
title=\lstname,
% if you want to add more keywords to the set
%morekeywords={*,...},
% Follow the chapter numbers
numberbychapter=true,
#1
}}
{}

%%%%%%%%%
% A version history entry in the appendix.
%%%%%%%%%
\newenvironment{verhist}[2]
	{\textbf{Version #1}\\\indent\xsmall(Released #2)\xnormalsize
	 \begin{itemize}}
	{\end{itemize}}
\newcommand{\removed}{\item \bold{Removed:}\xspace}
\newcommand{\obsolete}{\item \bold{Obsolete:}\xspace}
\newcommand{\deprecate}{\item \bold{Deprecated:}\xspace}
\newcommand{\info}{\item \bold{Info:}\xspace}
\newcommand{\newfeature}{\item \bold{NewFeature:}\xspace}
\newcommand{\changed}{\item \bold{Changed:}\xspace}
\newcommand{\bugfix}{\item \bold{BugFix:}\xspace}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Misc.
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\hyphenation{de-struct-ur-ing}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% The beginning of the document
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{document}

\frontmatter 

\title{\textbf{CL-MW}\\
\normalsize A Master-Slave Library for Distributed\\
Programming in Common Lisp\\
Version 0.1}
\author{Peter Keller\\psilord@cs.wisc.edu}
\date{\today}
\maketitle
\newpage
\tableofcontents
\newpage

\chapter{License}

The source code to \clmw, the example programs, and the
documentation source and contents are under the Apache 2 license:

\begin{center}
\framebox[5.1in]{
\begin{minipage}[t]{5.0in}
Copyright 2010 Peter K. Keller (psilord@cs.wisc.edu)\\

Licensed under the Apache License, Version 2.0 (the ``License"); you
may not use this file except in compliance with the License. You may
obtain a copy of the License at

\begin{center}
\url{http://www.apache.org/licenses/LICENSE-2.0}
\end{center}

Unless required by applicable law or agreed to in writing, software
distributed under the License is distributed on an ``AS IS" BASIS,
WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express
or implied. See the License for the specific language governing
permissions and limitations under the License.
\end{minipage}
}
\end{center}


\mainmatter

\chapter{Overview}

\section{Background}
\mw is a distributed computing paradigm where a master process
partitions work to one or more slave processes, collects the results,
and produces the required end solution from those partial results.
The work is usually of a fine to medium grained nature. The work
request, called a task, and the slave's response, called a result,
do not individually require large amounts of disk space, memory space,
or network resources.  The tasks may be ordered or unordered. Ordered
tasks must be assigned to a slave which may additionally hold
persistent information.  Unordered tasks run on any available slave and
are often the only kind of tasks supported by \mw systems.  Examples of
problems applicable to the \mw paradigm are: numerical optimization,
exploring game search trees, web-crawling, and Monte-Carlo simulations.

In many \mw execution environments, it is an unavoidable reality that
execute nodes asynchronously connect and unexpectedly disconnect from
the computation.  This is called slave churn. Many \mw systems accept
this reality and provide task scheduling algorithms such that when
a slave disconnects, times out, or otherwise is deemed unusable,
tasks assigned to that slave are recycled back into the task pool
to be distributed out to a different slave at a later time. If the
master process exits prematurely, then the slaves all die as soon as
they notice, as to not consume computing resources.

\mw systems may be coupled with an external batch scheduling
system. The batch system can manage resource acquisitions for the
slave processes and provide an environment to restart the computation
in the face of machine or other environmental failure.

\section{\clmw}
\clmw is a \mw implementation written in, and for, Common Lisp. The
design of the library's API was designed for ease of use and rapid
prototyping of \mw applications.  The library decouples management
of the task/result flow through the slaves from the act of spawning
slaves to simplify interaction with pre-existing batch systems. \clmw
has three main parts to be specified by the application author: one
or more \tas, a \ma, and optionally a \sa. \clmw implements a single
binary executable containing both the master and slave code.

The \ma produces tasks and inserts them into \clmw.  Tasks are data
packets destined for a specific \ta (and potentially a specific slave
as well) and which are stored in the master process.  \Tas are pieces
of code in the slave which process the tasks into results which
are sent back to the master process for consumption by the \ma.
\clmw maintains a pool of tasks running and waiting to be run.
While all of the tasks can be created during the \ma initialization,
tasks can also be added dynamically.  Tasks may be dynamically added
based on results from earlier tasks, or they may be dynamically added
to limit memory used to store them.  Tasks have meta-data associated
with them that can dictate where or in what manner the task should
be processed. This is known as a \tp.

An optional \sa allows arbitrary computation to happen in the slave
in between processing one or more task. An example of such a slave
computation is downloading a database upon slave startup which is
used by the \tas and then removing it when the slave shuts down.

\subsection{Task Algorithms}

A \ta is a piece of code written by the application author
which converts tasks into results in the slave.  The macro
\macro{define-mw-algorithm} defines a \ta. The parameter list of
this macro is similar to \macro{defun}. You specify a name and an
argument list. Unlike \macro{defun}, \key, \rest, and \optional\
arguments are currently not supported. The supplied code cannot return
a set of values with \func{values}. There must only be one value that
is returned.  These limitations will be removed in future versions
of \clmw.

Here is an example definition of a \ta which echos back its argument
unchanged. \Note The arguments accepted and the result returned
are that which you would have done had the \ta been defined with
\macro{defun}.

\begin{lisp}[caption=The \texttt{echo} Task Algorithm]
(define-mw-algorithm echo (val)
	val)
\end{lisp}

The result of expanding \macro{define-mw-algorithm} is a collection of
functions and a macro as defined in table~\ref{expanded-define-mw-algorithm}.

\begin{table}[hbt]
\begin{center}
\begin{tabular}{||l|l||} \hline
\bold{Symbol}							& \bold{Kind} \\ \hline
\func{echo}								& Function \\ \hline
\macro{mw-funcall-echo}					& Macro \\ \hline
\func{mw-set-target-number-for-echo}	& Function \\ \hline
\func{mw-get-target-number-for-echo}	& Function \\ \hline
\func{mw-pending-tasks-for-echo}		& Function \\ \hline
\func{mw-upto-target-number-echo}		& Function \\ \hline
\end{tabular}
\caption{\label{expanded-define-mw-algorithm}
		Expansion of \macro{define-mw-algorithm} for the \texttt{echo} \ta.}
\end{center}
\end{table}

The functions and macro created in expansion of the \emph{echo} \ta
are grouped into three sets: the \emph{echo} function itself--which is
the body of the \macro{define-mw-algorithm} macro, the task creation
macro \macro{mw-funcall-echo}, and a set of functions which allow
one to manage how many pending tasks for this \ta are queued.

\subsubsection{The \macro{mw-funcall-echo} Macro}

The macro \macro{mw-funcall-echo} creates a new task and separates
the arguments to the \textit{echo} function--ultimately called with
those arguments in the slave process, from the \tp associated with
the task.

The signature of \macro{mw-funcall-echo} is:

\begin{barelisp}
(mw-funcall-echo (str) 
                 (&key sid tag do-it-anyway (retry t)))
\end{barelisp}

This example call of \macro{mw-funcall-echo} shows the creation of a
new \textit{echo} task with an argument of \texttt{"Hello World"}.
All task arguments to the \ta must occur within the first set of
parentheses and in the order specified for the specific {\ta}'s
parameter list.  Processing this task will result in a result
structure given back to the \ma which contains the echoed string
\texttt{"Hello World"}.

\begin{barelisp}
(mw-funcall-echo ("Hello World"))
\end{barelisp}

\subsubsection{Task Policy}

The \tp associated with a task describes \emph{how} and \emph{where}
a task should be executed.  The \tp for a task is defined when a
task is created via the \macro{my-funcall-*} macro. Part of the
default \tp for a task to be considered unordered and to run on
any available slave.  Another part of the default is that if the
task running on an arbitrary slave---which then disconnects without
providing an answer, the task is reassigned to a different slave for
processing and this can happen many times.  The full default \tp is
specified on page ~\pageref{task-policy} as well as what each portion
of the policy means.

Through the \tp, one may assign tasks to run on previously acquired
ordered slaves. These ordered tasks will be run in the
order inserted by the \ma.  The \tp is directly responsible for a
ordered task possibly becoming \emph{unrunnable}. This happens when
the ordered slave which is processing the task disconnects. The
default \tp for ordered tasks is that any tasks being processed on
the disconnected slave \textit{or queued waiting to run on the slave}
become unrunnable and the task structures are given back to the \ma.

This example call of \macro{mw-funcall-echo} is the same as above with
respect to the task generated and the result expected. However, when
the result structure associated with this task is presented to the
\ma, the result will have in it the associated tag of \texttt{1234}.
The tag of a task may be any Lisp form.

\begin{barelisp}
(mw-funcall-echo ("Hello World") :tag 1234)
\end{barelisp}

\subsubsection{Task Algorithm Target Numbers}

Target numbers are values recorded by \clmw and set by the \ma which
represent the number of pending to run tasks for a \ta that should be
kept in memory at all times.  It is useful when a task generator in the
\ma can produce many more tasks than can fit into the master process's
memory or disk on the resource where the master process is running.

An analogy to the \clmw concept of target numbers is the temperature
setting of a thermostat. If one sets a thermostat to 70{\textdegree}F
then when the temperature falls below that, the furnace kicks in
and injects heat into the room until the target number is reached.
As the furnace heats up the room it may overheat it, but it generally
shouldn't since the goal is to keep the temperature stable at the
thermostat's setting.

In the same manner as the furnace, the \ma can use the target number
for a \ta to create the required number of tasks (which could be
zero if no new tasks are needed) into \clmw until the target number
is reached. The \ma can run millions or billions of tasks through
without having to have all of them in existence at once. The tasks
may be lazily generated as needed.

The target numbers themselves have no behavior on how \clmw processes
the tasks or enforces restricting the number of created tasks.
All target numbers do are provide a means so that the \ma can police
itself when creating tasks. The master is free to create more tasks
than specified in a target number without restriction (other than
running out of memory or other resources in the process).

Continuing the example of the \emph{echo} \ta, here is a description of the
signatures and meaning of this set of generated functions:\\

\begin{apientry}
{mw-set-target-number-for-echo \emph{value}}
{Function}
	A target number of \textit{echo} tasks the \ma would like to keep in
\clmw. Initially 0.
\end{apientry}

\begin{apientry}
{mw-get-target-number-for-echo}
{Function}
	Return the number of in memory tasks that exist for this \ta.
\end{apientry}

\begin{apientry}
{mw-pending-tasks-for-echo}
{Function}
	Return the number of tasks (both currently running and pending
	to run) for this \ta that are currently known about by \clmw.
\end{apientry}

\begin{apientry}
{mw-upto-target-number-echo}
{Function}
	A number of tasks which must be created by the \ma in order
	to reach the target number for this \ta. This function could
	return zero if the return value of \func{mw-get-target-number-for-echo} 
	is equal to or less than the return value of 
	\func{mw-pending-tasks-for-echo}.
\end{apientry}

\subsubsection{The General Target Number}

If an application author wishes to manage only the total
number of created tasks in memory independent of which \ta
they represent, then they can use the general target number
API as defined in section~\ref{general-target-number-api} on
page~\pageref{general-target-number-api}.  The number of tasks
\textit{up to} the general target number is the general target number
minus all pending tasks from any \ta.

\subsection{\label{master-algorithm}The Master Algorithm}

The macro \macro{define-mw-master} defines the \ma for a \clmw
application. There is only be one \ma per application. The \ma is
responsible for:

\begin{itemize}
\item Parsing non-\clmw command line arguments passed to the application process
\item Partitioning the main problem into sub-problems and creating tasks
\item Acquiring and managing ordered slaves
\item Calling the {\ma}'s event loop function
\item Processing the results returned by the slaves
\item Determining what to do when some tasks become unrunnable
\item Computing the final answer of the application from all results
\end{itemize}

The parameter list of this macro is:

\begin{barelisp}
(define-mw-master (argv) &body body)
\end{barelisp}

where \var{argv} is a variable--arbitrarily named and available in
the \var{body}, which will be bound to the command line argument
list. Any arguments destined to the \clmw library will have been
removed from the list before the \ma is invoked.  The arguments not
stripped out are left in the order specified on the command line.
The return value of the \ma must be an integer in the range of 0 and
255 (inclusive) and this value becomes the Unix return value for the
master process. If the return value is any other Lisp form other than
an integer between 0 and 255, the returned result will be 255.

Driving the \clmw master event loop is one of the main functions
of the \ma. The \ma accomplishes this by calling the function
\func{mw-master-loop} (or a variant of this function--see
page~\pageref{master-algorithm-api}). This function blocks and performs
network I/O to all slaves or any other background work in the \clmw
library. This function returns with a set of values that specify what
is available for the \ma to process (such as new results, arrival
or disconnection of ordered slaves, etc) only when there is some
event for the \ma to process.

\subsubsection{Slave Categorization}

The \ma can use the function \func{mw-allocate-slaves} to categorize
connecting slaves into the groups: \ord, \inter, and \un.  A connecting
slave is first used to satisfy the needs of the group \ord, then
\inter.  If enough slaves connect as to satisfy the needs for both
the \ord and \inter groups, then they are placed into the \un group.
Initially the \ord and \inter groups need 0 slaves and all slaves will
default to being placed in the \un group.

The \ord group means that the slave will \emph{only} run ordered tasks
dedicated to that slave. The \inter group means that a slave may run
unordered tasks in addition to ordered tasks dedicated to that slave
but the ordered tasks are given priority over any unordered tasks
which could run on that slave. Slaves in the \un group only run
unordered tasks.

When \inter or \ord slaves are needed and new slaves placed into
those groups, the \func{mw-master-loop} notifies the \ma (or
variant--see page~\pageref{master-algorithm-api}) that there are
ordered slaves ready for use. This notification happens with one of
the values returned by \func{mw-master-loop}. The \clmw application
author can use the function \\ \func{mw-get-connected-ordered-slaves} to
retrieve the list of connected slaves.

The function \func{mw-get-connected-ordered-slaves} returns a list
of \\ SLAVE-IDs which can be used as the \texttt{:sid} field with the
macro \macro{mw-funcall-*}.  If no ready ordered slaves are available,
then \bool{NIL} is returned. Connected ordered slaves accumulate in that
list until the \ma uses \\ \func{mw-get-connected-ordered-slave}
to retrieve them.  If at any time ordered slaves disconnect, the
function \func{mw-master-loop} will notify the \ma of the change
via one of its returned values.  The \ma can use the function
\func{mw-get-disconnected-ordered-slaves} to learn the SLAVE-IDs
of the disconnected ordered slaves. A slave may be in both lists at
once if it connected and then disconnected before the \ma was able
to retrieve either of the lists. There is no notification when an
\un slave connects or disconnects.

The \ma can free a slave from the \ord or \inter groups be using
\func{mw-deallocate-slaves} and \func{mw-free-slave}. These will move
ordered slaves to the \un group but only after they have completed
processing any assigned \ord tasks. \Note When a freed ordered slave
finishes processing the tasks assigned, it will move to the \un group
even though there may actually be more tasks destined for that slave.
In this case, the tasks will follow the task policy dictated by the
\ma when it created the task.

\subsubsection{Membership}

The membership token--an arbitrary string, is a token known between
the master and the slave. It must match for the master to accept the
slave and have it perform work. This is not a security measure. This
keeps the master and slave processes synchronized in heavy churn
situations where many masters and slaves from different computations
could be going up and down quickly. The major risk in high master
churn situations is port reuse of the master process. A port may
have master 1 bind to it, write a resource file, die, then later
master 2 from a different computation binds to the port, meanwhile
a slave using the original master 1 resource file tries to connect
to master 1 but actually connects to master 2.  Membership tokens
must be unique across \clmw application master processes running
concurrently on one machine. Unless otherwise specified with the
\OptionV{mw-resource-file}{filename} command line option, the membership
token will default to \texttt{"default-member-id"}.

\subsection{The Slave Algorithm}

The \sa is defined with \macro{define-mw-slave}.  The parameter list
of this macro is similar to \macro{define-mw-master}. This macro must
return an integer from 0 to 255 inclusive.  This portion of a \clmw
application is optional and may be left out entirely in an application.

\begin{barelisp}
(define-mw-slave (argv) &body body)
\end{barelisp}

The body of a \sa is usually a simple call to
\func{mw-slave-loop-simple}.  \func{mw-slave-loop-simple} will
wait for tasks to arrive from the master, process them, send the
results back, and will repeat until the master sends a shutdown
command. \func{mw-slave-loop-simple} returns 0 if the shutdown was
explicitly requested by the master and happened normally or 255
otherwise.

There are other slave looping function variants which allow the
slave loop function to return after a single, or group, of tasks
is finished.  These variants are used when the slave needs to set up
or tear down some files while it is working or otherwise manipulate
the environment around it in-between processing tasks. Please see
page~\pageref{slave-algorithm-api} for these other variants.

If no slave algorithm is specified in a \clmw application, then this
default \sa is automatically defined and used.

\begin{lisp}[caption=Default Slave Algorithm]
(define-mw-slave (argv)
  (mw-slave-loop-simple))
\end{lisp}

\subsection{Running a \clmw Application}

A \clmw application can be executed in two ways: interactively at a
REPL or as a dumped binary from the command line. When running in the
REPL, there should be a REPL for the master process and one each for
the slave processes. It is not recommended to start different threads
where one is the master and the rest are slaves.  From the REPL,
the \clmw entry point is the function \func{mw-initialize} which
takes a list of strings that represent the command line arguments
of the application. Running in the REPL is useful for debugging or
incremental development.

The recommended means of doing production runs with a \clmw
application is via a dumped binary created with the \clmw function
\func{mw-dump-exec}. When this function is called, the entire Lisp
image will be written into a binary and the Lisp image will exit
and any shared libraries which \func{mw-dump-exec} finds as being
local to the installation to SBCL or any used CL libraries will be
written to the current working directory. The entry point will be an
implementation specific function which does some bookkeeping and then
invokes \func{mw-initialize} with the command line arguments supplied.
In this form, the binary acts like any other client/server application
and you can easily run as many as you need.  If for some reason the
process gets an uncaught signal or other terminating error, a stack
trace created by SBCL's runtime will be emitted from the program to
facilitate debugging.

\clmw has a collection of settings which are adjusted via command line
options as described on page~\pageref{command-line-arguments}.

\subsection{Network I/O and Task/Result Size}

The underlying network implementation of \clmw is nonblocking and
fully asynchronous. A connection to a client is handled by a packet
buffer that is split into two pieces: a read buffer and a write
buffer. The initial size of each buffer is controllable.  The read
buffer can grow to a specified maximum size before the connection
is cut to the other side on account of the packet being too big.
The write buffer size is advisory at this time and only limit how
much can be written at one time instead of how large the write buffer
actually can be. This will be addressed in a future revision of \clmw.

The master process will internally group tasks into a whole network
packet and subsequently tell the slave how many results to group into
the network packet back to the master.  The grouping of tasks and
results amortizes the cost of sending data over TCP and increases
network utilization efficiency--at the cost of memory, of network
communication. It is up to the application author to understand
enough of their task and result size requirements to pick good
groupings so grouped tasks or results don't overflow the packet buffer
sizes. Understanding the scale of how many slaves will be connecting
to the master process will determine how big to make the initial
network buffer sizes and to what they should be capped as they grow.

\chapter{Downloading and Installing}

\section{Compatibility and Versioning}

\clmw will be considered in beta until it reaches the 1.0 version
number.  During this phase, the APIs or feature sets of \clmw
may change in a non-compatible ways with previous versions of
\clmw. Such compatibility or feature changes will be detailed
in the version history section of this document located in
appendix~\ref{version-history} on page~\pageref{version-history}.

\section{Supported Implementations}

\clmw is currently supported on/with: 

\begin{itemize}
\item SBCL 1.0.39.16 or later.
\item IOLib 0.7.0 or later.
\end{itemize}

\section{Official Release Tarballs}

\Todo

\section{Current Snapshots}

\Todo

\chapter{Writing Applications}

A \clmw application uses the \mwpackage and exists in its own
arbitrarily named package determined by the application author.
There exist three parts to a \clmw application: one or more \tas,
a single \ma, and a single \sa.

\section{Example: Hello World}

The purpose of this minimal example is to show how to create a \ta,
a \ma, and a \sa. The \ma will create tasks and process the results
from one or more slaves which connect to the master process. The \ta we
describe simply concatenates the string arguments with another string
and returns it. Both the master and the slave processes are assumed
to be on the same machine with both binding to the localhost interface.

We start with the unsurprising ASDF file for the hello-world \clmw application.

\begin{lisp}[caption=\file{cl-mw.examples.hello-world.asd}]
(asdf:defsystem #:cl-mw.examples.hello-world
  :depends-on (#:alexandria #:cl-mw)
  :components ( (:file "package")
                (:file "hello-world"
                       :depends-on ("package"))))
\end{lisp}

For this next listing we see that \func{mw-master} and \func{mw-slave}
are functions which are used for testing or debugging in the
REPL. Notice we re-export the \mwpackage symbol \func{mw-dump-exec}
from our application package which helps us easily save the lisp image
into a binary at a later time.

\begin{lisp}[caption=\file{package.lisp}]
(defpackage #:cl-mw.examples.hello-world
  (:use #:cl #:alexandria #:cl-mw)
  (:export #:mw-master
           #:mw-slave
           #:mw-dump-exec ))

(in-package :cl-mw.examples.hello-world)
\end{lisp}

For documentation purposes, we partition the main single file of the
implementation into parts which contain the \ta, the \ma, and the \sa.

The \ta accepts a regular Lisp string and also returns one.

\begin{lisp}[caption=\file{hello-world.lisp: \bold{Part 1 of 4}}]
(in-package :cl-mw.examples.hello-world)

(define-mw-algorithm hello (str)
  (concatenate 'string "Hello World: " str))
\end{lisp}

The \ma creates 10 tasks into \clmw and then continues
to call \func{mw-master-loop} until 10 results have been
processed.  When \func{mw-master-loop} returns, one or
more of these \clmw functions will return meaningful data,
depending upon the application: \func{mw-get-unrunnable-tasks},
\func{mw-get-results}, \func{mw-get-connected-ordered-slaves},\\
\func{mw-get-disconnected-ordered-slaves}.

\begin{lisp}[caption=\file{hello-world.lisp: \bold{Part 2 of 4}}]
(in-package :cl-mw.examples.hello-world)
(define-mw-master (argv)
    (unwind-protect
         (let ((num-tasks 10)
               (num-results 0))

           (dotimes (x num-tasks)
             (let ((str (format nil "Task ~A" x)))
               (mw-funcall-hello (str))))

           (while (/= num-results num-tasks)

             (mw-master-loop)

             (when-let ((results (mw-get-results)))
               (dolist (result results)
                 (let ((payload (mw-result-packet result)))
                   (incf num-results)

                   (format t "Got result from slave: ~S~%"
                           payload)))))
           0)

      (format t "Master algo cleanup form.~%")))
\end{lisp}

The \sa is very simple in our case. The function\\
\func{mw-slave-loop-simple} simply loops inside of \clmw processing
tasks until the master tells the slave to shut down, at which point
\func{mw-slave-loop-simple} returns 0 and the slave exits with
that return code. We could have left off this definition of a slave
algorithm altogether and used the default slave algorithm in a \clmw
application. We included it here as demonstration of how to write one.

\begin{lisp}[caption=\file{hello-world.lisp: \bold{Part 3 of 4}}]
(define-mw-slave (argv)
  (unwind-protect
       (mw-slave-loop-simple)
    (format t "Slave algo cleanup form.~%")))
\end{lisp}

We additionally specify two helper functions which are not part of
\clmw, nor technically the application, but allow us ease of debugging
and testing the application in the REPL.

\begin{lisp}[caption=\file{hello-world.lisp: \bold{Part 4 of 4}}]
(defun mw-master ()
  (mw-initialize 
    '("--mw-master" "--mw-slave-task-group" "10"
                    "--mw-master-host" "localhost"
                    "--mw-slave-result-group" "10")))

(defun mw-slave (port)
  (mw-initialize 
    `("--mw-slave" "--mw-master-host" "localhost"
                   "--mw-master-port"
                   ,(format nil "~D" port))))
\end{lisp}

\section{Running Hello-World in the REPL}

Now, let's run this example in the REPL so we can see how it
works. First, we'll set up and run the master process. We call our
master helper function to start the master process.  We're packaging
together 10 tasks to an idle slave and expecting 10 results back from
any particular slave. Otherwise 1 task will be sent and 1 result sent
back from the slave. Grouping the tasks or results together makes the
network communication more efficient.  The master is told to start
up on the \texttt{localhost} interface. There is no method to start
the master bound to all interfaces.

In the log output below, the member id token of the master and
slave is \bold{``default-member-id''}. In normal use, this should
probably be changed to be unique to the specific master/slave
computation. Please see the section on command line arguments on
page~\pageref{command-line-arguments} for how to do this.

\small
\begin{verbatim}
> sbcl
This is SBCL 1.0.39.16, an implementation of ANSI Common Lisp.
More information about SBCL is available at <http://www.sbcl.org/>.

SBCL is free software, provided as is, with absolutely no warranty.
It is mostly in the public domain; some portions are provided under
BSD-style licenses.  See the CREDITS and COPYING files in the
distribution for more information.
* (require :cl-mw.examples.hello-world)
[ Lots of output on compiling and loading libraries ]

* (use-package :cl-mw.examples.hello-world)

T

* (mw-master)
07/20/2010 23:15:42 [A] INIT MASTER "default-member-id"
07/20/2010 23:15:42 [A] MASTER READY 127.0.0.1:52942
\end{verbatim}
\normalsize

At this point, the master process has already created some hello
world tasks and is waiting for some slaves to connect. The output
lines with \texttt{[A]} in them are emitted as an audit trail by the
\clmw library.  The \bold{``default-member-id''} is the membership
token of the master which the slave must match. Let's start up a slave
with our helper slave initialization function and pass in the port
number of the master process---because for this example the helper
slave function assumes localhost.

\small
\begin{verbatim}
> sbcl
This is SBCL 1.0.39.16, an implementation of ANSI Common Lisp.
More information about SBCL is available at <http://www.sbcl.org/>.

SBCL is free software, provided as is, with absolutely no warranty.
It is mostly in the public domain; some portions are provided under
BSD-style licenses.  See the CREDITS and COPYING files in the
distribution for more information.
* (require :cl-mw.examples.hello-world)
[ Lots of output on compiling and loading libraries ]

* (use-package :cl-mw.examples.hello-world)

T

* (mw-slave 52942)
07/20/2010 23:23:46 [A] INIT SLAVE "default-member-id"
07/20/2010 23:23:47 [A] MASTER <- CONNECTED TO 127.0.0.1:52942 \
                        FROM 127.0.0.1:47768
07/20/2010 23:23:47 [A] MASTER -> ID SLAVE-0
07/20/2010 23:23:47 [A] MASTER -> 10 tasks (10 grouping)
07/20/2010 23:23:47 [A] MASTER <- 10 results
07/20/2010 23:23:47 [A] MASTER -> SHUTDOWN
Slave algo cleanup form.
07/20/2010 23:23:47 [A] FINI SHUTDOWN "default-member-id"
0
* 
\end{verbatim}
\normalsize

The last number is the return code of the slave function.

Meanwhile, let's see what the master emitted:

\small
\begin{verbatim}
07/20/2010 23:23:47 [A] NEW-CLIENT -> 127.0.0.1:47768
07/20/2010 23:23:47 [A] SLAVE-0 127.0.0.1:47768 -> \
                        ["default-member-id"] \
                        :connecting [:unordered]
07/20/2010 23:23:47 [A] SLAVE-0 -> :idle
07/20/2010 23:23:47 [A] SLAVE-0 <- 10 tasks
07/20/2010 23:23:47 [A] SLAVE-0 -> :busy
07/20/2010 23:23:47 [A] SLAVE-0 -> 10 results
07/20/2010 23:23:47 [A] SLAVE-0 -> :idle
Got result from slave: "Hello World: Task 0"
Got result from slave: "Hello World: Task 1"
Got result from slave: "Hello World: Task 2"
Got result from slave: "Hello World: Task 3"
Got result from slave: "Hello World: Task 4"
Got result from slave: "Hello World: Task 5"
Got result from slave: "Hello World: Task 6"
Got result from slave: "Hello World: Task 7"
Got result from slave: "Hello World: Task 8"
Got result from slave: "Hello World: Task 9"
Master algo cleanup form.
07/20/2010 23:23:47 [A] SLAVE-0 <- TRY-SHUTDOWN
07/20/2010 23:23:47 [A] SLAVE-0 -> :shutting-down
07/20/2010 23:23:47 [A] SLAVE-0 -> :disconnected
07/20/2010 23:23:47 [A] EOF -> 127.0.0.1:47768
07/20/2010 23:23:47 [A] FINI SHUTDOWN "default-member-id"
0
*
\end{verbatim}
\normalsize

\Note The audit lines have been reformatted slightly to fit. They do
not have the traditional shell line continuation characters in them.

We see that the master had packaged all ten tasks into one packet and
sent it to the slave. After getting the results--also in one packet,
back, it printed them out. At this point the results have equaled
the tasks in the \ma and it returns. \clmw enters the shutdown
phase where it actively tried to shut off all known slaves and then
exit with the return code the \ma generated. If a severe problem
arose during shutdown, then the return code will be set to 255.

\section{Producing an Executable}

The \mwpackage exports the function \func{mw-dump-exec} which saves
the Lisp image as an executable to the current working directory. We
recommend that this function be re-exported from the application
package built on top of the \mwpackage as shown previously in the
ASDF file for this example. Exporting this function makes it trivial
to produce an executable---one just \bold{require}s the package,
then \bold{use-package}s it, and then calls \func{mw-dump-exec}
to produce the binary. 

\func{mw-dump-exec} simplifies collecting required libraries that
may not be present on the slave system.  \func{mw-dump-exec} will
copy any currently loaded libraries with an absolute path into the
current working directory. For libraries without any path, it will
approximate the search algorithm used by \syscall{dlopen} to find an
absolute path for the library and then copy it to the current working
directory. \func{mw-dump-exec}, with the \keyword{ignore-libs} keyword
argument, can be told to ignore specific libraries loaded by the lisp
image. One would supply a list of strings representing unqualified
library names to be ignored. Libraries can also be remapped, with
the \keyword{remap-libs} keyword argument, from their unqualified
name to a specific path. An association list should be supplied
with \keyword{remap-libs} which maps unqualified library names to
absolute paths. Ignoring a library overrides a remap of a library,
and a remap of a library overrides the auto detection of the library's
absolute path.  \func{mu-dump-exec} will update the Lisp image to
look for the dumped libraries in the path \file{./} when the saved
executable is started.

How the lisp image is started before the executable is produced is
important.  We start \sbcl up with the \Option{disable-debugger} option
which tells \sbcl to dump a stack trace and exit when something has
gone wrong in the executable---such as the signaling of an unhandled
condition. Otherwise, \sbcl will drop into an interactive debugging
session and wait for input to arrive. Disabling the debugger prevents
the executable from having a problem and then consuming valuable
compute time on a resource waiting for input which will never come.

Dropping into the debugger is one of a few things in the execution
environment that can be altered with various command line options
to \sbcl. Another common adjustment to set is how big the heap is in
the Lisp image runtime.  The default runtime heap size is operating
system specific. On the Linux machine upon which I developed \clmw,
it was 512MB and so for each invocation of the master and slave
executable, about 512MB of memory will be requested from the operating
system---even if it isn't all used by the application. Depending upon
your \ma and \tas, you may need to tune the runtime heap size to fit
the computation requirements. Please see the \sbcl manual for more
tunable options as needed by your computation.

\small
\begin{verbatim}
> sbcl --disable-debugger
This is SBCL 1.0.39.16, an implementation of ANSI Common Lisp.
More information about SBCL is available at <http://www.sbcl.org/>.

SBCL is free software, provided as is, with absolutely no warranty.
It is mostly in the public domain; some portions are provided under
BSD-style licenses.  See the CREDITS and COPYING files in the
distribution for more information.
* (require :cl-mw.examples.hello-world)
[ Lots of output on compiling and loading libraries ]

* (use-package :cl-mw.examples.hello-world)

T

* (mw-dump-exec)

######################################
# Processing loaded shared libraries #
######################################
Shared-library: /home/psilord/content/code/lisp/clbuild/source\
                /iolib/src/syscalls/libiolib-syscalls.so...\
                dumping...fixating.
Shared-library: librt.so...looking up...found \
                /usr/lib/librt.so...dumping...fixating.

########################################################
#  Please package these libraries with your executable #
########################################################
./librt.so
./libiolib-syscalls.so

####################################
# Writing Master/Slave executable #
####################################
[undoing binding stack and other enclosing state... done]
[saving current Lisp image into ./a.out:
writing 3512 bytes from the read-only space at 0x01000000
writing 2256 bytes from the static space at 0x01100000
writing 38322176 bytes from the dynamic space at 0x09000000
done]
\end{verbatim}
\normalsize

\func{mw-dump-exec} iterated over all of the shared libraries being
used by the Lisp image. \func{mw-dump-exec} determined that the shared
library \file{libio-syscalls.so} used by IOLib (a package needed by
\clmw) must be included and the actual library file is copied into the
current working directory. Then the Lisp image is adjusted to look in
the path \file{./} for \file{libio-syscalls.so}.  \func{mw-dump-exec}
noticed that \file{librt.so} didn't have an absolute path but had a
successful search for an absolute path to the library.  This library
is also copied to the current working directory and the lisp image
adjusted to find it. If \func{mw-dump-exec} isn't told otherwise, the
name of the binary it dumps is \file{a.out}. You can supply a different
executable name to \func{mw-dump-exec}, see page~\pageref{mw-dump-exec}
for details.

If this executable is supplied with the same arguments
to \func{mw-initialize} as defined in the helper function
\func{mw-master} and another invocation started with the same
arguments to \func{mw-initialize} as defined in the helper function
\func{mw-slave} (adjusting for the master's host and port!), then
you will see similar output as the slave executes the master's tasks.

Here we see the executable and the shared libraries with which it should be
bundled when moved to another machine for execution:

\small
\begin{verbatim}
> ls a.out *.so
-rwxr-xr-x 1 psilord psilord 38948892 Jul 20 23:44 a.out*
-rw------- 1 psilord psilord     7235 Jul 20 23:44 libiolib-syscalls.so
\end{verbatim}
\normalsize

\Important Any dumped shared libraries \bold{must} exist in the
current working directory when the main binary is invoked for them to
be found by the restarting binary. Relative paths and the environment
variable \EnvVar{LD\_LIBRARY\_PATH} do not work properly.

\section{The Audit File}

The master and slave process both can write their
audit trail to a specified file. This is done with the
\OptionV{mw-audit-file}{file-name} command line option. When this
option is used, every written line above with an \texttt{[A]} in it
will be written to the specified audit file. Any other output that the
\ma or \sa creates will go to \var{*standard-output*} or to wherever
that is bound.

\Limitation The audit files do not rotate and can grow unboundedly. The
audit file will be appended to if it exists upon start of the master
or slave process.

\clmw does minimal statistics bookkeeping. The audit files can be used
to answer questions about the application's run. For example, how many
slaves are connected, what is the slave churn rate, on what subnet are
the slaves, or how many tasks were processed for a given time interval.

\Note The format of the audit file may change in a future revision of \clmw.

\chapter{Interfacing with Existing Batch Systems}

\clmw is designed to work with various pre-existing batch systems. Due
to this design decision, \clmw has no provision for starting up slaves
on a remote machine, moving files between machines, detecting and killing
run away slaves, managing user identity, storing or transmitting
credentials, or enforcing authorization policies for resource use.
These, and many other features, are the general things which batch
systems usually provide.

What \clmw does provide is a means for interaction with a batch system
called the \rfile.  The master process, when configured to do so,
will periodically write information into the \rfile, which details:
liveness of the master process, if the computation is still in progress,
how many slaves the master desires, and exactly how to start up those
slaves. As the batch system provides the resources requested by the
master, the master process adjusts the numbers accordingly. The
\rfile constitutes a feedback loop between \clmw and the batch
system actions which allow slaves to join the computation.

The \rfile is written when the command line option\\
\OptionV{mw-resource-file}{file-name} is used with the
master process. By default the master will rewrite it
every 300 seconds (5 minutes) with new information. This
can be controlled by the command line option\\
\OptionV{mw-resource-file-update-interval}{integral-seconds}.

The \rfile is written in a convenient to read Lisp format and is
intended to be read by another process specific to the batch scheduler
whose responsibility it is to acquire resources from said batch
scheduler. The batch scheduler is directly notified in the \rfile
if the {\ma}'s computation is in progress or finished.

\Note The slave process can also read the \rfile in order to determine
the master host, port, and member-id to which it should connect and
if the computation is still in progress or finished.  Depending upon
the batch scheduler, having the slave read the \rfile directly can
be a very advantageous.

The internals of the \rfile are described on
page~\pageref{resource-file}.

\section{Condor}

Condor is a versatile, robust, and free batch scheduling system
available from \url{http://www.cs.wisc.edu/condor}. It has the ability
to maintain high throughput for tens of thousands of jobs on tens of
thousands of resources where the job constraints and the resource
constraints are symmetrically honored and can manage supplementary
file transfers on behalf of a job. Most importantly, Condor will try
very hard to execute your job even in the face of machine failure or
many other problems and is a very suitable batch system with which
to host \clmw.

\subsection{Interfacing \clmw with Condor}

The basic properties of Condor which we will be utilizing with respect
to \clmw are: how Condor performs file transfer of needed files for
a job from the submit node to an execute node, and the conditions
under which a job may leave the job queue.

Concerning the file transfer, Condor can be told to transfer the
job's input files to the remote execute node just before the job is
about to start.  Condor will do this \emph{each time} a job tries to
run when it has been sitting idle in the queue. We use this fact to
copy over the \rfile written by the master over to the slave so the
slave knows where to connect.

We also use the fact that Condor can control when a job leaves the
queue by forbidding the slave to leave the queue unless it gets told
to shutdown by the master, or otherwise exits with the return code
of zero. In these cases, if the slave had exited due to a connection
refused attempt, it will just go back to idle, and be restarted later.

Both of these together allow us a simple statement of reliability.
Suppose the master dies without producing a completed answer.
The slave, having noticed that the master closed the connection
without having been told to explicitly shut down, will exit with
a non-zero status--and stay in the queue due to the job policy
we enforce with Condor.  If the slave was run again and tried to
connect using a stale resource file (due to the master being down
for an extended period of time), it will exit with a non-zero status
value, again staying in the queue.  Now suppose the master restarted
and wrote the new \rfile.  When the slave runs again, the new \rfile
gets moved to it and it will connect with the currently running master.
Finally, if the master has finished and written the final resource
file stating the computation is finished, then any slaves that start
up with that particular \rfile will immediately exit with a status
zero allowing them to leave the queue. Of course, if a slave ever
gets told to shutdown properly by the master, and does so, then it
will exit with an exit code of 0 and also leave the queue.

The particular interface described in this section is a very simple one
and doesn't push the feedback loop of the \rfile deeply at all. It
could be extended much more if there were an actual process outside
of \clmw and managed by Condor which watches the \rfile and actively
participates in the feedback loop with the instance of \clmw.

\subsubsection{A Simple Interface to Condor}

This example describes the Condor interface for the \texttt{ping}
example supplied with \clmw.

I will present two Condor submit files, one for a single master
process, and one for a static cluster of slave processes. The master
will write a \rfile and the slaves--utilizing file transfer, will
read it and know where to connect. The \rfile path must be unique
to each \clmw computation submitted to the same scheduler daemon
in Condor and must match between the master's submit file and the
slave's submit file. No dynamic adjustment of resource acquisition is
done in this example.

\subsubsection{The Master Process}

The following submit file details how the master process is to be run.
It will be a scheduler universe job that restricts membership of
the slaves to be the cluster and process number of the submitted
job, and will communicate with the slaves by means of the \rfile
\file{resource-file.rsc}. We assume the needed libraries associated
with the \texttt{ping} program are present alongside the executable in
the submit directory and we submit the job with \textit{condor\_submit}
in that directory.

An audit file is specified based upon the cluster and process id of
the job.  It will be filled with information about who and how the
slaves connect and what work is given to them. The \file{master.out}
and \file{master.err} file will hold the real standard output and
error output from the \ma.

\Note We specify the slave executable name directly, even though
the master would use argv[0] to determine the name of itself if we
did not specify the slave executable. We do this because Condor
renames the argv[0] spawned processes to a special name such as
\texttt{condor\_exec.\textit{JOBID}} where \texttt{\textit{JOBID}} is
an XXX.YYY number representing the Condor specific cluster and process
id of the job.  However, since the executable will be invoked (by
default) in the current working directory of the scheduler universe
job, the master can still determine the true name of the specified
executable and we don't have to specify the full path.

\begin{verbatim}
universe = scheduler
executable = ./ping
arguments = --mw-master \
--mw-slave-task-group 100 \
--mw-slave-result-group 100 \
--mw-resource-file resource-file.rsc \
--mw-slave-executable ping \
--mw-audit-file master.$(CLUSTER).$(PROCESS).audit \
--mw-member-id $(CLUSTER).$(PROCESS)

output = master.out
error = master.err
log = master.log

notification = NEVER

queue 1
\end{verbatim}

When this job is submitted, it should start immediately and create the \rfile.

\subsubsection{The Slave Processes}

The following submit file submits a static cluster of vanilla jobs
which are the slaves which will continuously attempt to connect to
the master using the \rfile \file{resource-file.rsc} until such
time as they are told explicitly to shut down by the master, or they
read a \rfile which dictates the computation is over.

\begin{verbatim}
universe = vanilla
executable = ./ping
arguments = --mw-slave \
--mw-resource-file resource-file.rsc

output = slaves.$(PROCESS).out
error = slaves.$(PROCESS).err
log = slaves.log

should_transfer_files = YES
when_to_transfer_output = ON_EXIT
transfer_input_files = libiolib-syscalls.so,resource-file.rsc

notification = NEVER

on_exit_remove = (ExitBySignal == False) && (ExitCode == 0)

queue 1000
\end{verbatim}

One thousand jobs will be submitted into this cluster, and no more
or less will be allocated regardless of the \texttt{:slaves-needed}
setting in the \rfile. This is because there is no true overseer
for the \rfile which is managing the resource acquisition desired by
the \ma. These slaves will stay in the queue until they are told to
shutdown by the master or they see the computation has been finished
in the \rfile.  Notice that the \rfile is transmitted as an input
file and under Condor this means to transmit it anew every time the
job is rerun. We also send over any shared libraries or other files
the executable needs.

In addition, we specify the \texttt{on\_exit\_remove} policy for the
job, which states to only let the job leave the queue if it had not
exited with a signal and the exit code was zero.

\subsection{Environmental Concerns}

Running binaries across a host of machines which often will differ in:
OS revisions, physical capabilities, and network will invariably bring
to the forefront edge cases in binary compatibility or scalability
problems. Here we describe a few common scenarios and their usual
solution.

\subsubsection{Memory Requirements}

Depending upon the memory capabilities of the resource slots in
the pool (suppose they only have 384MB each), a slave may run once,
consume 512MB (suppose the unchanged default heap size) which Condor
records as the memory usage for the job, get preempted for some reason,
and then never run again because no slot in the pool will accept a
512MB job anymore.

This is fixed by either adding \texttt{Requirements = Memory > 0}
(or whatever fits your needs) to the slave's submit file or adjusting
the fixed runtime heap size with command line arguments to \sbcl
when you create the executable. The latter choice is safer since it
models the true resource requirements your application needs and does
a better job of preventing thrashing. The former is more useful for
testing purposes.

\subsubsection{Network or Disk Bandwidth}

Another environmental concern is the network or disk bandwidth of
the submit machine as potentially thousands of slaves (potentially
simultaneously) have their executables, shared libraries, and other
files transferred off of the submit machine and onto the execute slots.
In practice this often isn't a problem, but it is good to know what
to do if it becomes one.

The \textit{condor\_schedd} config file entries
\texttt{JOB\_START\_DELAY} and\\ \texttt{JOB\_START\_COUNT} can be used
to limit the job start rate to restrict network and disk bandwidth
when bursts of jobs begin running.

\subsubsection{Dynamic Linking}

Since a \clmw application is a dynamically linked binary, it
will need to find and load its required libraries at run time.
When the binary is moved from the submit host to the execute host,
it may be possible that the execute host may not have a suitable
dynamic library available, or more rarely, a suitable kernel syscall
interface the job needs. In this event, the job (in our case, the
slave) will (often) die with a SIGKILL and go back to idle (due to
our \texttt{on\_exit\_remove} policy). It could be possible for a
slave to continuously match to a machine upon which it cannot run and
accumulate badput. Condor has various means to address this issue
so please refer to the manual.

\chapter{Technical Specification}

\section{Command Line Arguments}
\label{command-line-arguments}

These are the command line arguments the \clmw library accepts. These
command line arguments are stripped from the argv before the argv is
handed to the \ma.

\begin{description}
\item[\Option{mw-help}]
    Emit the usage and exit.
\item[\Option{mw-version-string}]
    Emit the version string and exit.
\item[\Option{mw-master}]
    Run the executable in Master Mode. Required if \Option{mw-slave} is not set
	and must be first on the command line.
\item[\Option{mw-slave}]
    Run the executable in Slave Mode. Required if \Option{mw-master} is not set
	and must be first on the command line.
\item[\OptionV{mw-master-host}{ip-address-or-hostname}]
    When in Master Mode, it is the interface (either the hostname or
    the ip address) to which the master should bind and is emitted to
    the resource file if any such file is written.
    When in Slave Mode, it is the hostname, or ip address, to which
    the slave process should connect and get work.
\item[\OptionV{mw-master-port}{port}]
    To which port should the slave connect for work.
\item[\OptionV{mw-max-write-buffer-size}{size-in-bytes}]
    How big the network writing buffer should be before rejecting the write.
\item[\OptionV{mw-max-read-buffer-size}{size-in-bytes}]
    How big the network reading buffer should be before rejecting the read.
\item[\OptionV{mw-client-timeout}{seconds}]
    How many seconds should the master wait for a client to respond
    when the master is expecting a response.
\item[\OptionV{mw-audit-file}{filename}]
    A file in which the audit trail of the process is stored.
\item[\OptionV{mw-resource-file}{filename}]
    Describes the resources needed by the master for a higher level batch
    system to honor.\\
	When in master mode this file contains information concerning:
	\begin{itemize}
		\item The time stamp of when the file was written.
		\item The member id of the master group.
		\item The update interval of when this file will be written again.
		\item How many slave processes are needed by the master.
		\item The full path to the slave executable.
		\item The complete arguments to the slave in order for it to
			connect to the currently running master process which 
			produced this file.
    \end{itemize}
    When in slave mode:
	\begin{quotation}
      Determine the master-host, master-port, and member-id to which
      the slave should connect by reading it from the resource file.
      The ordering of this command line option in relation to
      \Option{mw-master-host}, \Option{mw-master-port}, and 
	  \Option{mw-member-id} is
      important. If \Option{mw-master-host}, \Option{mw-master-port}, and/or
      \Option{mw-member-id} are specified before this argument then the
      resource file will overwrite the command line specification,
      and vice versa. If the resource file does not exist, then this
      knowledge is ignored (but warned about) if \Option{mw-master-host}
      and \Option{mw-master-port} are present.
	\end{quotation}
\item[\OptionV{mw-resource-file-update-interval}{seconds}]
    How many seconds between updating the resource file with current
    information.
\item[\OptionV{mw-slave-task-group}{positive-integer}]
    How many tasks are grouped into a network packet being sent
    to a slave process. If the packet is larger than the maximum
    size of the read buffer of the slave, the slave will abort the
    read. Defaults to 1.
\item[\OptionV{mw-slave-result-group}{positive-integer}]
    How many completed results should be grouped into a network packet
    being sent from the slave to the master. If the packet is larger than the
    maximum size of the read buffer for the master, then the master will
    abort the connection to the slave. Defaults to 1.
\item[\OptionV{mw-member-id}{string}]
    This is a token which must match between the slave and the master. It is
    used to insecurely identify a working group of masters and slave. In a
    harsh environment with many masters and slaves going up and down, this
    acts as a simple sanity check that the correct slaves are connected to the
    correct master process. Default is the string "default-member-id".
\item[\OptionV{mw-slave-executable}{path-to-executable}]
    This specifies the absolute path to a slave executable. It is used
    when writing the resource file only.
\end{description}

\section{The API}

The \clmw library is in the \mwpackage and it is used by the application
package built on top of \clmw. The exported symbols in the \mwpackage are:

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\apiheader{The Task Algorithm}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%%%
\begin{apientry}
{define-mw-algorithm \emph{name} (\emph{parameters*}) \&body \emph{body}}
{Macro}
Defines a \ta with name \emph{name}. The arguments passed to this
call are exactly those which were passed into the \genmacroname{mw-funcall-}
form for the \ta.

\Limitation The \emph{parameters} list is restricted to being \emph{required}
parameters only. 

\Limitation A \ta may not return multiple values or a
function or closure. The latter restriction is due to the inability
to serialize a closure from the slave to the master.
\end{apientry}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\apiheader{Task Computation Function Generated by \macro{define-mw-algorithm}}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{apientry}
{\textit{name} \textit{parameters*}}
{Function}
This is the function which actually performs the work of the \ta. It
accepts the parameters specified and returns the last expression in
the body supplied to the \ta macro.
\end{apientry}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\apiheader{Task Submission Macro Generated by \macro{define-mw-algorithm}}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%
\begin{apientry}
{mw-funcall-\textit{name} (\emph{parameters}) \&key\\
\indent \emph{sid} \emph{tag} \emph{do-it-anyway} (\emph{retry} t)}
{Macro}
This is a destructuring macro which will insert a single new task
of the \ta named by \emph{name}  into \clmw. The \emph{parameters}
are in the same order as the parameter list for the defined \ta and
are evaluated before being packed into the task structure. The other
parameters describe a behavior which together constitute the \tp for
a submitted task.

\begin{description}
\phlabel{task-policy}
\item[sid \textit{SLAVE-ID}] Send the task to a specific slave denoted by 
					\textit{SLAVE-ID}.
                    If \bool{NIL}, this task is considered \un, otherwise it is 
					a \ord task. 
\item[tag \textit{FORM}] A form which will appear unchanged in the result
			structure associated with the computed task. The default is 
			\bool{NIL}.
\item[do-it-anyway {[T \textit{or} NIL]}] If the task was a 
							\ord task and the slave disconnected, then should
							this task be moved into the \un group (yes if T),
							or become unrunnable (yes if \bool{NIL})? 
							By default \ord tasks become unrunnable if the 
							associated slave is disconnected. 
\item[retry {[T \textit{or} NIL]}] If an unordered task was assigned to a 
			slave and the slave went away, then this controls if we should
			retry on a different slave or if the task becomes unrunnable. If
			this test passes then :do-it-anyway is consulted in the case of
			\ord tasks. 
\end{description}
\end{apientry}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\apiheader{Specific Target Number API Generated by \macro{define-mw-algorithm}}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%%%
\begin{apientry}
{mw-set-target-number-for-\textit{name} \emph{value}}
{Function}
Sets the target number for the \ta specific to \emph{name} to
\emph{value}, which is clamped to zero or greater.  This represents
the maximum number of pending tasks for this \ta that
the \ma would like to keep in memory at once. This target number is advisory
and the \ma can insert more tasks than indicated by the target number. The
default target number for any specific \ta is 0.  
\end{apientry}

%%%
\begin{apientry}
{mw-get-target-number-for-\textit{name}}
{Function}
Returns the target number for the number of desired tasks to
keep in memory for the \ta specific to \emph{name}.
\end{apientry}

%%%
\begin{apientry}
{mw-pending-tasks-for-\textit{name}}
{Function}
Return how many tasks are in memory (and not running on any slaves) specific
to the \ta \emph{name}.
\end{apientry}

%%%
\begin{apientry}
{mw-upto-target-number-\textit{name}}
{Function}
Returns the number of tasks the \ma would have to create in order
to reach the desired target number for \ta \emph{name}.
\end{apientry}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\apiheader{\phlabel{general-target-number-api}The General Target Number API}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%
\begin{apientry}
{mw-set-target-number \emph{value}}
{Function}
Sets the general target number for all tasks regardless of \ta. This is
only advisory and more tasks could be created into \clmw by the \ma.
\end{apientry}

%%%
\begin{apientry}
{mw-get-target-number}
{Function}
Return the current value of the general task target number. The
default value for the general target number is 0.
\end{apientry}

%%%
\begin{apientry}
{mw-pending-tasks}
{Function}
Return how many tasks of any kind are waiting to be scheduled to slaves.
\end{apientry}

%%%
\begin{apientry}
{mw-upto-target-number}
{Function}
Return how many tasks of any kind should be created by the master in order
to reach the general target number for all tasks.
\end{apientry}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\apiheader{\phlabel{master-algorithm-api}The Master Algorithm}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%
\begin{apientry}
{define-mw-master (\emph{argv}) \&body \emph{body}}
{Macro}
Defines the \ma for the application of which there may only be one.
When the \ma has finished computation, it must return an integer from 0 to 255
which will become the return code of the process. If this doesn't happen,
the return integer will be 255.

\Note If no master algorithm is specified in a \clmw application. An
audit line will be emitted stating this fact and the master computation
will shut down immediately. A return code of 255 will happen in
this case.

Parameter \emph{argv} will be the command line arguments passed to
the executable or to \func{mw-initialize} with the \clmw specific
arguments stripped out.
\end{apientry}

%%%
\begin{apientry}
{mw-master-loop \&key (\emph{timeout} .05)}
{Function}
Enter the \clmw system loop processing I/O and other library tasks until
one or more of these events happen:
\begin{itemize}
\item Some tasks become unrunnable.
\item There are pending results from slaves.
\item Sequential slaves have connected to the computation.
\item Sequential slaves have disconnected from the computation.
\end{itemize}

When one or more of these events happen the function will return the
4 values: 

\begin{enumerate}
\item Number of unrunnable tasks
\item Number of ready results
\item Number of newly connected and unprocessed ordered slaves
\item Number of newly disconnected and unprocessed ordered slaves
\end{enumerate}

Parameter \emph{timeout} is a time unit in real seconds which should
be waited in the Network IO multiplexing library before timing out
due to inactivity.  In the case of this function, it means we perform
bookkeeping work inside of the \clmw library and enter back into the
loop if no meaningful events occurred. Setting this value too low will
result in excessive CPU usage by the master process.

\end{apientry}

%%%
\begin{apientry}
{mw-master-loop-iterate \&key (\emph{timeout} .05)}
{Function}
Enter the \clmw system loop processing a \emph{single} pass of network
I/O and other library tasks. After this call one or more of the same events
as described in \func{mw-master-loop} \emph{may} have happened.

Parameter \emph{timeout} is a time unit in real seconds which should
be waited in the Network IO multiplexing library before timing out
due to inactivity.  In the case of this function, it means we return
the 4 values as described in \func{mw-master-loop}. Setting this value
too low could result in excessive CPU utilization.

\end{apientry}

%%%
\begin{apientry}
{mw-get-unrunnable-tasks}
{Function}
Return all currently unrunnable task structures in a list or \bool{NIL} if none.
\end{apientry}

%%%
\begin{apientry}
{mw-get-results}
{Function}
Return all currently finished result structures in a list or \bool{NIL} if none.
\end{apientry}

%%%
\begin{apientry}
{mw-get-connected-ordered-slaves}
{Function}
If there are any connected ordered slaves ready for use, this will
retrieve the list of slave ids or \bool{NIL} if none. In practice each slave
id is a string, but generally they are an opaque data structure used
to uniquely identify a slave. You should use \func{equal} to check
quality between slave ids.
\end{apientry}

%%%
\begin{apientry}
{mw-get-disconnected-ordered-slaves}
{Function}
If any ordered slaves have become disconnected, return a list of
their slave ids. You may use \func{equal} to compare against other
slave ids.
\end{apientry}

%%%
\begin{apientry}
{mw-allocate-slaves \&key (\emph{amount} 1000) (\emph{kind :unordered})}
{Function}
There are three kinds of groups for which slaves can be allocated:
\ord, \inter, \un.  When a slave initially connects for work, it is
placed into one of the three groups.  The order of group fulfillment
is \ord, \inter, \un. If both \ord and \inter are full, then any
connecting slaves go over to the \un group. The total number of desired
slaves for all groups is written into the resource file as the number of
needed slaves. This function can cause slaves in the \un group to move to
the groups desired.

It is valid for the \un group to contain more than the allocation for
it.  The default allocation for all groups is 0.
\end{apientry}

%%%
\begin{apientry}
{mw-deallocate-slaves \&key (\emph{amount} 0) (\emph{kind} :unordered)}
{Function}
This does not stop any slaves from processing any tasks, but it does lower
the number of slaves desired, clamped to zero, of any of the of group
\un, \inter, or \ord as specified. This relates to what is written in the
resource file by the master process.
\end{apientry}

%%%
\begin{apientry}
{mw-free-slave \emph{slave-id}}
{Function}
Move the slave specified by \emph{slave-id} into the \un \\ group
after it completes whatever tasks it may be running and adjust the
desired slave amounts for the group the slave was in. This does not
evict or otherwise stop currently allocated tasks from running on
that slave. The slave's group is only changed once all of the tasks
it is currently running are computed.  \end{apientry}

%%%
\begin{apientry}
{mw-num-runnable-tasks}
{Function}
Returns the number of runnable tasks which includes tasks that were
sent out and currently executing on slaves.
\end{apientry}

%%%
\begin{apientry}
{mw-num-unrunnable-tasks}
{Function}
Returns the number of unrunnable tasks in waiting to be consumed out
of \clmw with \func{mw-get-unrunnable-tasks}.
\end{apientry}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\apiheader{\phlabel{slave-algorithm-api}The Slave Algorithm}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%
\begin{apientry}
{define-mw-slave (\emph{argv}) \&body \emph{body}}
{Macro}
Defines the \sa for the application of which there may only be one.
When the \sa has finished computation, it must return an integer from 0 to 255
which will become the return code of the process. If this doesn't happen,
the return integer will be 255.

Parameter \emph{argv} will be the command line arguments passed to
the executable or to \func{mw-initialize} with the \clmw specific
arguments stripped out.

\Note If no \sa is specified in a \clmw application, then the default \sa
defined in listing~\ref{default-slave-algorithm} is used. An audit line
entry will occur stating that the \clmw default \sa is being used.

\begin{lisp}[label=default-slave-algorithm,caption=Default Slave Algorithm]
(define-mw-slave (argv)
  (mw-slave-loop-simple))
\end{lisp}

\end{apientry}

%%%
\begin{apientry}
{mw-slave-loop \&key (\emph{timeout} .05)}
{Function}
Process all pending tasks and return control to the \sa.

This function will return 6 values in this order:
\begin{description}
\item[master-disconnect]
	Did the master close the connection to the client (or under some conditions
	\clmw wanted to immediately exit due to some problem in the environment).
	T if the master cut the connection or the library wanted to exit, 
	\bool{NIL} otherwise.
\item[explicit-shutdown]
	Did the master send a shutdown command to the slave according to the
	master/slave protocol?  T if it did and \bool{NIL} if it didn't.
\item[total-results-completed]
	The number of total results which have been completely processed by the 
	slave.
\item[num-tasks]
	A number which is how many tasks are yet to be processed.
\item[num-results]
	The number of results that are currently waiting to be sent back. This is 
	affected by the master process with the command line parameter 
	\Option{mw-slave-result-group}.
\item[result-grouping]
	The number of results which must be grouped together before being sent
	back (or if there are no more tasks to compute whatever results are
	pending to go back get sent back).
\end{description}

Parameter \emph{timeout} is a time unit in real seconds which should
be waited in the Network IO multiplexing library before timing out
due to inactivity.  In the case of this function, it means we perform
bookkeeping work inside of the \clmw library and then return into
the \sa.  Setting this value too low will result in excessive CPU
usage by the master process.

\end{apientry}

%%%
\begin{apientry}
{mw-slave-loop-iterate \&key (\emph{timeout} .0001)}
{Function}
Process a \emph{single} pending task, inspect the network buffers for
more work to do, and return control to the \sa. This will generally
be extremely slow and hence has a short timeout. It returns the same values
as \func{mw-slave-loop} and there may or may not have been any new tasks
sent by the master in that time.

Parameter \emph{timeout} is a time unit in real seconds which should
be waited in the Network IO multiplexing library before timing out
due to inactivity.
\end{apientry}

%%%
\begin{apientry}
{mw-slave-loop-simple \&key (\emph{timeout} .05)}
{Function}
Process all pending tasks form the master and wait for more. Only
return when the master says to shutdown or there was a bad error and
return 0 or 255 respectively.

Parameter \emph{timeout} is a time unit in real seconds which should
be waited in the Network IO multiplexing library before timing out.
In the case of this function, it means we perform bookkeeping work
inside of the \clmw library and begin waiting again for more tasks
from the master, or a shutdown command. Setting this value too low
will result in excessive CPU usage by the slave process.
\end{apientry}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\apiheader{The Task Structure}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%
\begin{apientry}
{mw-task-sid \emph{task-structure}}
{Function}
Returns the slave-id for which the \emph{task-structure} was destined. 
If the task is \un, then \bool{NIL} is returned.
\end{apientry}

%%%
\begin{apientry}
{mw-task-tag \emph{task-structure}}
{Function}
Return the associated tag object for this \emph{task-structure}, or \bool{NIL}
if not set.
\end{apientry}

%%%
\begin{apientry}
{mw-task-packet \emph{task-structure}}
{Function}
Retrieve, as a list, the arguments specific to the algorithm for
which this \emph{task-structure} was created.
\end{apientry}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\apiheader{The Result Structure}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%
\begin{apientry}
{mw-result-algorithm \emph{result-structure}}
{Function}
Return an uppercase string which is the name of the \ta that produced this
\emph{result-structure}.
\end{apientry}

%%%
\begin{apientry}
{mw-result-sid \emph{result-structure}}
{Function}
Return the slave id of the slave which produced this \emph{result-structure}.
\end{apientry}

%%%
\begin{apientry}
{mw-result-tag \emph{result-structure}}
{Function}
Retrieve the unmodified tag associated with the original \emph{task-structure}
for this \emph{result-structure}.
\end{apientry}

%%%
\begin{apientry}
{mw-result-compute-time \emph{result-structure}}
{Function}
Return the length of time in seconds which represents how long it took to
compute this \emph{result-structure}.
\end{apientry}

%%%
\begin{apientry}
{mw-result-packet \emph{result-structure}}
{Function}
Retrieve the actual returned form of the \ta which produced this 
\emph{result-structure}.
\end{apientry}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\apiheader{Miscellaneous API}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%
\begin{apientry}
{mw-initialize (\emph{argv}\\
\indent \&key (\emph{system-argv} \emph{sb-ext:*posix-argv*}))}
{Function}
The entry point into \clmw. The parameter \emph{argv} is a list of
strings which represent the argument list to the library. Anything
not a \clmw specific argument will be passed to the \ma or the \sa
in the same order as it was on the command line.
\end{apientry}

%%%
\begin{apientry}
{mw-version-string}
{Function}
Return a string which represents the version number for this library.

\Note The format and meaning of this string may change in the future.
\end{apientry}

%%%
\begin{apientry}
{mw-zero-clamp \emph{value}}
{Function}
If the \emph{value} is less than zero, then return 0, otherwise return the
\emph{value}.
\end{apientry}

%%%
\phlabel{mw-dump-exec}
\begin{apientry}
{mw-dump-exec \&key (\emph{exec-name} "a.out")\\
\indent \emph{ignore-libs} \emph{remap-libs}}
{Function}

Produce an executable named \emph{exec-name}, which is \file{a.out}
by default, and copy any shared libraries needed by the application
into the current working directory.

Any shared libraries loaded in the lisp image which are already
an absolute path will be copied verbatim to the current working
directory. Any unqualified libraries will be transformed by an
algorithm approximating the search algorithm of \syscall{dlopen}
into absolute paths and then copied to the current working directory.
The dumped shared libraries must be shipped with the executable to
the target machine.

The parameter \emph{ignore-libs} is a list of strings where each string
is an unqualified library name. These libraries will be ignored by
\func{mw-dump-exec}. If this parameter is \bool{NIL}, the default,
then no libraries are ignored.

The parameter \emph{remap-libs} is an association list of strings
where the first string is an unqualified library name and the second
an absolute path to a library that will be copied to the current
working directory in place of what is found in the lisp image. If this
parameter is \bool{NIL}, the default, then no libraries are remapped.

This interface may change in the future.

\Limitation The dumped libraries must exist in the current working directory
	when the executable is run.
\end{apientry}

%%%
\begin{apientry}
{while \emph{test-expr} \&body \emph{body}}
{Macro}
A ubiquitous macro which implements the usual ``while'' loop control flow.
\end{apientry}

\section{Resource File}
\label{resource-file}

Each form in the \rfile is a two item list where the first item
is the attribute name as a keyword, and the second an arbitrary Lisp
form whose schema depends upon the specific attribute. They take the
form of:\\

\noindent\texttt{(keyword \textit{form})}\\

The current attributes for the \rfile in this version of \clmw are:

\begin{description}
\item[:computation-status] 
	The value is either the keyword \texttt{:in-progress} or the
	keyword \texttt{:finished}. It represents if the \ma thinks
	the computation is finished or not. If a slave reads a \rfile
	with \texttt{:computation-status} being \texttt{:finished},
	it will exit immediately with a status of zero.

\item[:timestamp] 
	The value is an integer which represents the universal time when the file
	was written.

\item[:member-id] 
	The value is a string which must match in the master and slave.

\item[:update-interval]
	The value is an integer which represents the number of seconds since the
	timestamp after which the resource file will be re-written. The default 
	is 300 seconds.

\item[:slaves-needed]
	This value represents the raw number of slaves the \ma has requested in
	order to complete its task.

\item[:slave-executable]
	This value is a list where the first element is a string
	representing the full path to the executable which is the
	slave executable, and the second element is a list of strings
	representing full paths to any shared libraries that have to
	be moved along with the executable.

\item[:slave-arguments]
	This value is a list of strings which are the command line arguments,
	in order, with which the slave is to be spawned.
\end{description}

An example file:

\begin{lisp}[caption=Contents of a sample \rfile]
;; Status of the computation
(:computation-status :in-progress)
;; Time Stamp of Resource File
(:timestamp 3488766071)
;; Member ID
(:member-id "default-member-id")
;; Update Interval (sec) of Resource File
(:update-interval 300)
;; Slaves Needed
(:slaves-needed 1000)
;; Slave Executable and Shared Libs
(:slave-executable 
   ("/home/psilord/bin/a.out" ("/home/psilord/bin/libiolib-syscalls.so")))
;; Slave Arguments
(:slave-arguments ("--mw-slave" "--mw-master-host" "black" 
                   "--mw-master-port" "47416"))
\end{lisp}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Appendices
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\appendix

\chapter{Example Application Descriptions}

\section{Hello-World}
The canonical example detailed in this manual.

\section{Ping}
The \ta for this example returns \keyword{ping-ok} if presented with
a \keyword{ping} argument, or otherwise \keyword{ping-not-ok}. The
interesting aspect of this example is the use of the \emph{general
target number} API for the in memory tasks. Billions of tasks can
be run through this application, but only a small number are kept in
memory at any give time to prevent memory exhaustion.

\section{Monte-Carlo-Pi}
This example implements the Monte Carlo algorithm to compute pi. Each
task runs N trials and returns N and the number of trials in the
circle. The master keeps a running sum of the total trials and the
total number of trials in the circle. At the end of the maximum
number of iterations, the approximation algorithm is performed with
the computed ratio and the approximation to pi is produced.

\section{Higher-Order}
This example shows that \tas can be quite versatile. Here the
\textit{horder} \ta compiles a function presented to it as an argument
and applies it to the data also presented to it returning the result
of the application. The \ma creates a unique function for each task
and associates it with the data for that task. All results are printed
out when gotten back from the slaves. While this example shows the
fundamental sketch of producing higher order \tas, more work would
be needed to handle signaled errors or other problems that could show
up in the \ta.

\chapter{\label{version-history}Version History}

\begin{verhist}{0.1}{MM/DD/YYYY}
\info Initial release of \clmw.
\end{verhist}

\chapter{Acknowledgements}

I would like to graciously thank: my wife Stephanie--who often put
up with me vanishing for hours on end to write and test \clmw, Greg
Thain, Mick Beaver, and Alan De Smet, whom acted as sounding boards
for the implementation and gave great feedback in the design of the
system, manual, and how a user other than me would want to interact
with it. In addition, I would like to thank the various denizens at
\texttt{comp.lang.lisp} and \texttt{\#lisp} for answering my many
questions about Lisp.

\clmw is not an official product from the Condor Project. It is written
by me in my free time. If you would like to use a C++ version of the
\mw paradigm then check out \texttt{Condor-MW} form Condor's website.

\backmatter

\end{document}



